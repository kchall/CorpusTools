{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from math import *\n",
    "import itertools\n",
    "# from multiprocessing import Queue # might need this?\n",
    "# import Queue   # this is Queue in 2.7, but queue in 3...not actually called in script?\n",
    "# import copy\n",
    "from math import factorial\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (exceptions.py, line 318)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"corpustools/exceptions.py\"\u001b[0;36m, line \u001b[0;32m318\u001b[0m\n\u001b[0;31m    'an environment not included in the list you selected.'), file=f)\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# these don't work -- why not?\n",
    "from corpustools.exceptions import FuncLoadError\n",
    "from .io import save_minimal_pairs\n",
    "from corpustools.corpus.classes.lexicon import EnvironmentFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_minpair(first, second, corpus_context, segment_pairs, environment_filter): # Q: how do I find or figure out what type of object each of these parameters should be? e.g. is segment_pairs a list? a tuple? a list of tuples? (corpus_context and environment_filter presumably are defined elsewhere...but still, it would be useful to know what their structure is)\n",
    "    # according to the doc strings of minpair_fl (below): segment_pairs : list of length-2 tuples of str\n",
    "    \"\"\"Return True iff first/second are a minimal pair.\n",
    "    Checks that all segments in those words are identical OR a valid segment pair\n",
    "    (from segment_pairs) and fit the environment_filter, and that there is at least\n",
    "    one difference between first and second.\n",
    "    \"\"\"\n",
    "    first = getattr(first, corpus_context.sequence_type) # Q: how do I find out what .sequence_type does?\n",
    "        # in contextmanagers.py: sequence_type is a string that is defined as \"Sequence type to evaluate algorithms on (i.e., 'transcription')\"\n",
    "        # so this is saying get the attribute labeled in corpus_context.sequence_type (\"transcription\" or \"vowels\" or whatever) of the item named 'first'\n",
    "        second = getattr(second, corpus_context.sequence_type)\n",
    "    if len(first) != len(second):\n",
    "        return False\n",
    "    has_difference = False\n",
    "    for i in range(len(first)):\n",
    "        if first[i] == second[i]:\n",
    "            continue\n",
    "        elif (conflateable(first[i], second[i], segment_pairs) # this is defined below\n",
    "            and fits_environment(first, second, i, environment_filter)): # this is defined below\n",
    "            has_difference = True\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    if has_difference:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conflateable(seg1, seg2, segment_pairs):\n",
    "    \"\"\"Return True iff seg1 and seg2 are exactly one of the segment pairs\n",
    "    in segment_pairs (ignoring ordering of either).\n",
    "\n",
    "    seg1 and seg2 will never be identical in the input.\n",
    "    \"\"\"\n",
    "    for segment_pair in segment_pairs:\n",
    "        seg_set = set(segment_pair)\n",
    "        if seg1 in seg_set and seg2 in seg_set:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(is_minpair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment_pairs = [(\"p\", \"t\"), (\"s\", \"f\")] # yay, this is the structure I thought it should be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seg_set = set(segment_pairs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f', 's'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg1 = \"s\"\n",
    "seg2 = \"f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if seg1 in seg_set and seg2 in seg_set:\n",
    "    print True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Q: why do we need a set? does \"in\" not work with tuples?\n",
    "# A: the set will be the UNIQUE members of the list / tuple / etc.\n",
    "print(seg1 in segment_pairs[1])\n",
    "print(seg2 in segment_pairs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q: ok, so \"in\" works with tuples not just sets -- why do we need to make the tuple into a set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fits_environment(w1, w2, index, environment_filter):\n",
    "    \"\"\"Return True iff for both w1 and w2 (tiers), the environment\n",
    "    of its i'th element fits passes the environment_filter.\n",
    "    \"\"\"\n",
    "    if not environment_filter:\n",
    "        return True\n",
    "\n",
    "    def ready_for_re(word, index):\n",
    "        w = [str(seg) for seg in word]\n",
    "        w[index] = '_'\n",
    "        return ' '.join(w)\n",
    "\n",
    "    w1 = ready_for_re(w1, index)\n",
    "    w2 = ready_for_re(w2, index)\n",
    "    env_re = make_environment_re(environment_filter) # this is defined below\n",
    "\n",
    "    return (bool(re.search(env_re, w1)) and bool(re.search(env_re, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ready_for_re(word, index):\n",
    "        w = [str(seg) for seg in word]\n",
    "        w[index] = '_'\n",
    "        return ' '.join(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h i p _ o p o t a m u s'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_for_re(\"hippopotamus\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_environment_re(environment_filter): # again, need to know structure of env_filter\n",
    "    if environment_filter.lhs:\n",
    "        re_lhs = ' '.join(['('+('|'.join([seg for seg in position])+')') for position in environment_filter.lhs])\n",
    "        re_lhs = re_lhs.replace('#', '^')\n",
    "    else:\n",
    "        re_lhs = ''\n",
    "\n",
    "    if environment_filter.rhs:\n",
    "        re_rhs = ' '.join(['('+('|'.join([seg for seg in position])+')') for position in environment_filter.rhs])\n",
    "        re_rhs = re_rhs.replace('#', '$')\n",
    "    else:\n",
    "        re_rhs = ''\n",
    "\n",
    "    if re_lhs and not re_lhs.endswith('^)'):\n",
    "        re_lhs += ' '\n",
    "    if re_rhs and not re_rhs.endswith('($'):\n",
    "        re_rhs = ' ' + re_rhs\n",
    "    return re_lhs + '_' + re_rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OK, here is the main minimal pair func load function\n",
    "# need to know format of context manager\n",
    "def minpair_fl(corpus_context, segment_pairs,\n",
    "        relative_count_to_relevant_sounds = False, relative_count_to_whole_corpus = True, distinguish_homophones = False,\n",
    "        environment_filter = None,\n",
    "        stop_check = None, call_back = None):\n",
    "    \"\"\"Calculate the functional load of the contrast between two segments\n",
    "    as a count of minimal pairs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus_context : CorpusContext\n",
    "        Context manager for a corpus\n",
    "    segment_pairs : list of length-2 tuples of str\n",
    "        The pairs of segments to be conflated.\n",
    "    relative_count_to_relevant_sounds : bool, optional\n",
    "        If True, divide the number of minimal pairs by the total count\n",
    "        by the total number of words that contain either of the two segments.\n",
    "        # changed the name of this from \"relative_count\" to \"relative_count_to_relevant_sounds\"\n",
    "        # set its default to False above\n",
    "    relative_count_to_whole_corpus : bool, optional\n",
    "        If True, divide the number of minimal pairs by the total number of words \n",
    "        in the corpus (regardless of whether those words contain the target sounds).\n",
    "        Defaults to True.\n",
    "    distinguish_homophones : bool, optional\n",
    "        If False, then you'll count sock~shock (sock=clothing) and\n",
    "        sock~shock (sock=punch) as just one minimal pair; but if True,\n",
    "        you'll overcount alternative spellings of the same word, e.g.\n",
    "        axel~actual and axle~actual. False is the value used by Wedel et al.\n",
    "    environment_filter : EnvironmentFilter\n",
    "        Allows the user to restrict the neutralization process to segments in\n",
    "        particular segmental contexts\n",
    "    stop_check : callable, optional\n",
    "        Optional function to check whether to gracefully terminate early\n",
    "    call_back : callable, optional\n",
    "        Optional function to supply progress information during the function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple(int or float, list)\n",
    "        Tuple of: 0. if `relative_count_to_relevant_sounds`==False and \n",
    "        `relative_count_to_whole_corpus`==False, an int of the raw number of\n",
    "        minimal pairs; if `relative_count_to_relevant_sounds`==True, a float of that\n",
    "        count divided by the total number of words in the corpus that\n",
    "        include either `s1` or `s2`; if `relative_count_to_whole_corpus`==True, a\n",
    "        float of the raw count divided by the total number of words in the corpus; \n",
    "        and 1. list of minimal pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    if stop_check is not None and stop_check():\n",
    "        return\n",
    "\n",
    "    ## Count the number of words in the corpus (needed if relative_count_to_whole_corpus is True)\n",
    "    num_words_in_corpus = len(corpus_context) # Q: not sure if this will work; modelled from the for loop below\n",
    "    \n",
    "    ## Filter out words that have none of the target segments\n",
    "    ## (for relative_count_to_relevant_sounds as well as improving runtime)\n",
    "    contain_target_segment = []\n",
    "    if call_back is not None:\n",
    "        call_back('Finding words with the specified segments...')\n",
    "        call_back(0, len(corpus_context))\n",
    "        cur = 0\n",
    "\n",
    "    all_target_segments = list(itertools.chain.from_iterable(segment_pairs)) # creates a list of target segments from the list of tuples\n",
    "    for w in corpus_context: # loops through the words in the context manager?\n",
    "        if stop_check is not None and stop_check():\n",
    "            return\n",
    "        if call_back is not None:\n",
    "            cur += 1\n",
    "            if cur % 100 == 0:\n",
    "                call_back(cur)\n",
    "        tier = getattr(w, corpus_context.sequence_type)\n",
    "        if any([s in tier for s in all_target_segments]):\n",
    "                contain_target_segment.append(w)\n",
    "    if stop_check is not None and stop_check():\n",
    "        return\n",
    "\n",
    "    ## Find minimal pairs\n",
    "    minpairs = []\n",
    "    if call_back is not None:\n",
    "        call_back('Finding minimal pairs...')\n",
    "        if len(contain_target_segment) >= 2:\n",
    "            call_back(0,factorial(len(contain_target_segment))/(factorial(len(contain_target_segment)-2)*2))\n",
    "        cur = 0\n",
    "    for first, second in itertools.combinations(contain_target_segment, 2):\n",
    "        if stop_check is not None and stop_check():\n",
    "            return\n",
    "        if call_back is not None:\n",
    "            cur += 1\n",
    "            if cur % 100 == 0:\n",
    "                call_back(cur)\n",
    "        if is_minpair(first, second, corpus_context, segment_pairs, environment_filter):\n",
    "            ordered_pair = sorted([(first, getattr(first, corpus_context.sequence_type)),\n",
    "                                   (second, getattr(second, corpus_context.sequence_type))],\n",
    "                                   key = lambda x: x[1]) # sort by tier/transcription\n",
    "            minpairs.append(tuple(ordered_pair))\n",
    "\n",
    "    ## Generate output ## STILL NEED TO EDIT THIS\n",
    "    if not distinguish_homophones:\n",
    "        actual_minpairs = {}\n",
    "\n",
    "        for pair in minpairs:\n",
    "            if stop_check is not None and stop_check():\n",
    "                return\n",
    "            key = (pair[0][1], pair[1][1]) # Keys are tuples of transcriptions\n",
    "            if key not in actual_minpairs:\n",
    "                actual_minpairs[key] = (pair[0][0], pair[1][0]) # Values are words\n",
    "            else:\n",
    "                pair_freq = pair[0][0].frequency + pair[1][0].frequency\n",
    "                existing_freq = actual_minpairs[key][0].frequency + \\\n",
    "                                actual_minpairs[key][1].frequency\n",
    "                if pair_freq > existing_freq:\n",
    "                    actual_minpairs[key] = (pair[0][0], pair[1][0])\n",
    "        result = sum((x[0].frequency + x[1].frequency)/2\n",
    "                    for x in actual_minpairs.values())\n",
    "    else:\n",
    "        result = sum((x[0][0].frequency + x[1][0].frequency)/2 for x in minpairs)\n",
    "\n",
    "    if relative_count_to_relevant_sounds and len(contain_target_segment) > 0:\n",
    "        result /= sum(x.frequency for x in contain_target_segment)\n",
    "        \n",
    "        # Q: do I need to put anything here between these if statements (like make it an else if)? or can I just have them back to back?\n",
    "        # relative_count_to_relevant_sounds and relative_count_to_whole_corpus won't both be true\n",
    "        # but both COULD be false, in which case, result should just stay as the raw count \n",
    "        # that I assume is returned above -- elif will ensure that only one runs; if will allow both to run\n",
    "        \n",
    "    if relative_count_to_whole_corpus:\n",
    "        result = result / num_words_in_corpus\n",
    "    \n",
    "    return (result, minpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 't'), ('s', 'f')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p', 't', 's', 'f']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.chain.from_iterable(segment_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_target_segments = list(itertools.chain.from_iterable(segment_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6032a1f7b268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtier\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_target_segments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# any(): Returns True if any element of the iterable is true.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tier' is not defined"
     ]
    }
   ],
   "source": [
    "any([s in tier for s in all_target_segments])\n",
    "# any(): Returns True if any element of the iterable is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
